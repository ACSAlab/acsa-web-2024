---
title: "swVoN"
# father-team: HPC # 根小组填空，填对应父亲小组的文件名
leader:
- Jun Shi
members:
---

Task 1: 国产超算平台(神威)上大模型训练优化

目标：在SW超算系统上构建大模型基础技术栈，支持各类大模型的高效训练，完成swVoN大模型的开发。

进度：  大模型训练框架适配和移植（SW-Megatron）
LLAMA-7B有监督微调（SFT）流程正确性验证
针对神威平台大模型训练流程给出完整Profiling
面向神威平台实现了高效并行训练策略
面向神威平台开发了支持混精训练的BF16算子库
在8K节点上采样250Btoken，完成LLAMA-7B的预训练流程正确性验证，与通用平台对齐。
在最高四分之一机(32K)节点上，完成了LLAMA-65B的混精预训练调试和性能分析。
单节点计算效率从0.32TFLOPS提升到3.4TFLOPS。

	人员： 石军、刘波、朱子琦、田永劭、吴若晗、李奇
